{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this project, you will build a neural network of your own design to evaluate the MNIST dataset.\n",
    "\n",
    "Some of the benchmark results on MNIST include can be found [on Yann LeCun's page](http://yann.lecun.com/exdb/mnist/) and include:\n",
    "\n",
    "88% [Lecun et al., 1998](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\n",
    "95.3% [Lecun et al., 1998](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\n",
    "99.65% [Ciresan et al., 2011](http://people.idsia.ch/~juergen/ijcai2011.pdf)\n",
    "\n",
    "MNIST is a great dataset for sanity checking your models, since the accuracy levels achieved by large convolutional neural networks and small linear models are both quite high. This makes it important to be familiar with the data.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell contains the essential imports you will need – DO NOT CHANGE THE CONTENTS! ##\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell for first time only and restart the kernel\n",
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import FloatProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "Specify your transforms as a list if you intend to .\n",
    "The transforms module is already loaded as `transforms`.\n",
    "\n",
    "MNIST is fortunately included in the torchvision module.\n",
    "Then, you can create your dataset using the `MNIST` object from `torchvision.datasets` ([the documentation is available here](https://pytorch.org/vision/stable/datasets.html#mnist)).\n",
    "Make sure to specify `download=True`! \n",
    "\n",
    "Once your dataset is created, you'll also need to define a `DataLoader` from the `torch.utils.data` module for both the train and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "#Import necessary libraries\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose(\n",
    "[\n",
    "    #Transform the pixel values(0-255) to a float tensor with range (0.0-1.0)\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "    #Normalize the tensor\n",
    "    transforms.Normalize((0.5), (0.5))\n",
    "])\n",
    "\n",
    "# Create training and validation set and define training dataloader\n",
    "train_validation_data = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "\n",
    "#Seperate 80% training data 20% validation data\n",
    "total_length = len(train_validation_data)\n",
    "train_length = int(total_length*0.8)\n",
    "validation_length = total_length - train_length\n",
    "train_data, validation_data = random_split(train_validation_data, [train_length, validation_length])\n",
    "\n",
    "#Training dataset loader\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "#Validation dataset loader\n",
    "validation_loader = DataLoader(dataset=validation_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# Create test set and define test dataloader\n",
    "test_data = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justify your preprocessing\n",
    "\n",
    "In your own words, why did you choose the transforms you chose? If you didn't use any preprocessing steps, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformation 1: ToTensor()**\n",
    "This transformation is necessary because the pixel values range from 0 to 255. Such higher value are not supported by Tensor. So we convert the data in the range (0, 1). \n",
    "\n",
    "**Transformation 2: Normalize()**\n",
    "Activation functions better work with data with mean value 0.5 and standard deviation of 0.5. MNIST data has only one channel, so we normalize this channel only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Dataset\n",
    "Using matplotlib, numpy, and torch, explore the dimensions of your data.\n",
    "\n",
    "You can view images using the `show5` function defined below – it takes a data loader as an argument.\n",
    "Remember that normalized images will look really weird to you! You may want to try changing your transforms to view images.\n",
    "Typically using no transforms other than `toTensor()` works well for viewing – but not as well for training your network.\n",
    "If `show5` doesn't work, go back and check your code for creating your data loaders and your training/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell contains a function for showing 5 images from a dataloader – DO NOT CHANGE THE CONTENTS! ##\n",
    "def show5(img_loader):\n",
    "    dataiter = iter(img_loader)\n",
    "    \n",
    "    batch = next(dataiter)\n",
    "    labels = batch[1][0:5]\n",
    "    images = batch[0][0:5]\n",
    "    for i in range(5):\n",
    "        print(int(labels[i].detach()))\n",
    "    \n",
    "        image = images[i].numpy()\n",
    "        plt.imshow(image.T.squeeze().T)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of each image is: [1, 28, 28]\n"
     ]
    }
   ],
   "source": [
    "# Explore data\n",
    "#Show some Training data\n",
    "show5(train_loader)\n",
    "\n",
    "#Shape of each image\n",
    "dataiter = iter(train_loader)\n",
    "batch = next(dataiter)\n",
    "image = batch[0][0]\n",
    "shape = list(image.shape)\n",
    "height = shape[-2]\n",
    "width = shape[-1]\n",
    "print(f\"Shape of each image is: {list(image.shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of classes is 10\n"
     ]
    }
   ],
   "source": [
    "#Check number of Classes\n",
    "n_classes = len(set(train_validation_data.targets.tolist()))\n",
    "\n",
    "print(f\"Total number of classes is {n_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your Neural Network\n",
    "Using the layers in `torch.nn` (which has been imported as `nn`) and the `torch.nn.functional` module (imported as `F`), construct a neural network based on the parameters of the dataset.\n",
    "Use any architecture you like. \n",
    "\n",
    "*Note*: If you did not flatten your tensors in your transforms or as part of your preprocessing and you are using only `Linear` layers, make sure to use the `Flatten` layer in your network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Neural Networkc\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, height, width, n_class):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #Height and width of the input image\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        \n",
    "        #input size to 380 hidden units\n",
    "        self.fc1 = nn.Linear(height*width, 380)\n",
    "        #Rectified Linear Activation\n",
    "        self.relu1 = nn.ReLU()\n",
    "        #30% dropout to overcome overfitting\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        #380 hidden unit to 380 hidden unit\n",
    "        self.fc2 = nn.Linear(380, 380)\n",
    "        #Rectified Linear Activation\n",
    "        self.relu2 = nn.ReLU()\n",
    "        #30% dropout to overcome overfitting\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        #380 hidden unit to n_class output unit\n",
    "        self.fc3 = nn.Linear(380, n_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #Flatten the input image\n",
    "        x = x.view(-1, self.height*self.width)\n",
    "        #Forward pass the input through the network\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify a loss function and an optimizer, and instantiate the model.\n",
    "\n",
    "If you use a less common loss function, please note why you chose that loss function in a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the model\n",
    "model = Net(height, width, n_classes)\n",
    "\n",
    "#Upload the model to GPU memory if available\n",
    "model.to(device)\n",
    "\n",
    "#Specify loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Specify optimizer\n",
    "#Learnrate = 0.001\n",
    "#L2 regularization by specifying weight decay to prevent overfitting\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running your Neural Network\n",
    "Use whatever method you like to train your neural network, and ensure you record the average loss at each epoch. \n",
    "Don't forget to use `torch.device()` and the `.to()` method for both your model and your data if you are using GPU!\n",
    "\n",
    "If you want to print your loss **during** each epoch, you can use the `enumerate` function and print the loss after a set number of batches. 250 batches works well for most people!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "----------\n",
      "\tAccuracy:\n",
      "\t\tTrain: 93.6271%\n",
      "\t\tValidation: 95.3917%\n",
      "\tLoss:\n",
      "\t\tTrain: 0.2050\n",
      "\t\tValidation: 0.1498\n",
      "\n",
      "Epoch: 2\n",
      "----------\n",
      "\tAccuracy:\n",
      "\t\tTrain: 93.4937%\n",
      "\t\tValidation: 95.9750%\n",
      "\tLoss:\n",
      "\t\tTrain: 0.2050\n",
      "\t\tValidation: 0.1373\n",
      "\n",
      "Epoch: 3\n",
      "----------\n",
      "\tAccuracy:\n",
      "\t\tTrain: 93.6562%\n",
      "\t\tValidation: 95.9167%\n",
      "\tLoss:\n",
      "\t\tTrain: 0.1992\n",
      "\t\tValidation: 0.1368\n",
      "\n",
      "Epoch: 4\n",
      "----------\n",
      "\tAccuracy:\n",
      "\t\tTrain: 93.9125%\n",
      "\t\tValidation: 95.5667%\n",
      "\tLoss:\n",
      "\t\tTrain: 0.1954\n",
      "\t\tValidation: 0.1462\n",
      "\n",
      "Epoch: 5\n",
      "----------\n",
      "\tAccuracy:\n",
      "\t\tTrain: 93.6208%\n",
      "\t\tValidation: 96.0917%\n",
      "\tLoss:\n",
      "\t\tTrain: 0.2070\n",
      "\t\tValidation: 0.1259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating the training and validation loop\n",
    "\n",
    "#Number of epochs\n",
    "epochs = 5\n",
    "\n",
    "#List for loss history\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "\n",
    "#Training and validation loop\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    ##Training##\n",
    "    \n",
    "    #Set the model in traing mode\n",
    "    model.train()\n",
    "    \n",
    "    #Initialize training loss for each epoch\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    #Count correct predictions while training\n",
    "    train_correct = 0\n",
    "    \n",
    "    #Loop for each batch of data\n",
    "    for i, data in enumerate(train_loader):\n",
    "        #input images and labels\n",
    "        inputs, labels = data\n",
    "        \n",
    "        #Upload data to GPU memory if available\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Set gradient value value to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Output of forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        #Calculate cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #Backpropagate the loss\n",
    "        loss.backward()\n",
    "        \n",
    "        #Optimize the model by updating weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Extract model predictions\n",
    "        _, predicts = torch.max(outputs.data, 1)\n",
    "        \n",
    "        #Calculate total number of correct predictions by comparing with labels\n",
    "        num_corrects = (predicts == labels).sum().item()\n",
    "        \n",
    "        #Update the total number of correct predictions\n",
    "        train_correct += num_corrects\n",
    "        \n",
    "        #Record the training loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    ##Validation##\n",
    "    \n",
    "    #Set the model in validation mode\n",
    "    model.eval()\n",
    "    \n",
    "    #Initialize validation loss\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    #Count correct predictions\n",
    "    val_correct = 0\n",
    "    \n",
    "    #Loop for each batch of data\n",
    "    for i, data in enumerate(validation_loader):\n",
    "        #input images and labels\n",
    "        inputs, labels = data\n",
    "        \n",
    "        #Upload data to GPU memory if available\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Output of forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        #Calculate cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #Extract model predictions\n",
    "        _, predicts = torch.max(outputs.data, 1)\n",
    "        \n",
    "        #Calculate total number of correct predictions by comparing with labels\n",
    "        num_corrects = (predicts == labels).sum().item()\n",
    "        \n",
    "        #Update the total number of correct predictions\n",
    "        val_correct += num_corrects\n",
    "        \n",
    "        #Record the training loss\n",
    "        val_loss += loss.item()\n",
    "        \n",
    "    #Print accuracy and loss for each epoch\n",
    "    \n",
    "    #Calculating average loss and accuracy\n",
    "    num_train_batches = len(train_loader)\n",
    "    num_val_batches = len(validation_loader)\n",
    "    avg_train_loss = train_loss/num_train_batches\n",
    "    avg_val_loss = val_loss/num_val_batches\n",
    "    avg_train_accuracy = train_correct/train_length\n",
    "    avg_val_accuracy = val_correct/validation_length\n",
    "    \n",
    "    #Record training and validation loss history\n",
    "    train_loss_history.append(avg_train_loss)\n",
    "    val_loss_history.append(avg_val_loss)\n",
    "    \n",
    "    #Messages\n",
    "    messages = {\n",
    "        \"1\" : f\"Epoch: {epoch + 1}\",\n",
    "        \"2\" : \"-\"*10,\n",
    "        \"3\" : \"\\tAccuracy:\",\n",
    "        \"4\" : f\"\\t\\tTrain: {100*avg_train_accuracy:.4f}%\",\n",
    "        \"5\" : f\"\\t\\tValidation: {100*avg_val_accuracy:.4f}%\",\n",
    "        \"6\" : \"\\tLoss:\",\n",
    "        \"7\" : f\"\\t\\tTrain: {avg_train_loss:.4f}\",\n",
    "        \"8\" : f\"\\t\\tValidation: {avg_val_loss:.4f}\\n\"    \n",
    "    }\n",
    "    \n",
    "    #Print message\n",
    "    for i in range(len(messages)):\n",
    "        print(messages[f\"{i+1}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training loss (and validation loss/accuracy, if recorded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your model\n",
    "Using the previously created `DataLoader` for the test set, compute the percentage of correct predictions using the highest probability prediction. \n",
    "\n",
    "If your accuracy is over 90%, great work, but see if you can push a bit further! \n",
    "If your accuracy is under 90%, you'll need to make improvements.\n",
    "Go back and check your model architecture, loss function, and optimizer to make sure they're appropriate for an image classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving your model\n",
    "\n",
    "Once your model is done training, try tweaking your hyperparameters and training again below to improve your accuracy on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving your model\n",
    "Using `torch.save`, save your model for future loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
